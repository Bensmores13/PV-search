{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygeos\n",
    "import pandas as pd\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "gpd.options.use_pygeos=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solarpv.utils import get_utm_zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import geometry, ops, wkt\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach:\n",
    "- get geoms for latlon boxes and buffer 10km\n",
    "- get geoms for unitary union of 10km buffers\n",
    "- map latlon boxes to unitary union\n",
    "- map unitary union to individual arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('./data/SPV_newmw.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['representative_point'] = gdf['geometry'].representative_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = pd.DataFrame(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['geometry'] = gdf['geometry'].apply(lambda el: el.wkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_WGS = pyproj.Proj(\"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buffer_geom(geom, dist):\n",
    "    \n",
    "    #geom = wkt.loads(geom_str)\n",
    "    utm_zone = get_utm_zone(geom.representative_point().y, geom.representative_point().x)\n",
    "    \n",
    "    PROJ_UTM = pyproj.Proj(proj='utm',zone=utm_zone, ellps='WGS84')\n",
    "    \n",
    "    wgs2utm = partial(pyproj.transform, PROJ_WGS, PROJ_UTM)\n",
    "    utm2wgs = partial(pyproj.transform, PROJ_UTM, PROJ_WGS)\n",
    "    \n",
    "    shp_utm = ops.transform(wgs2utm, geom)\n",
    "    shp_utm_buffer = shp_utm.buffer(dist)\n",
    "    \n",
    "    shp_wgs_buffer = ops.transform(utm2wgs,shp_utm_buffer)\n",
    "    \n",
    "    return shp_wgs_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get latlon boxes\n",
    "gdf['nearest_x.5'] = gdf['representative_point'].apply(lambda el: np.floor(el.x*2)/2)\n",
    "gdf['nearest_y.5'] = gdf['representative_point'].apply(lambda el: np.floor(el.y*2)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_pairs = list(set([tuple(cc) for cc in gdf[['nearest_x.5','nearest_y.5']].values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_geoms = [geometry.box(cc[0],cc[1],cc[0]+0.5, cc[1]+0.5) for cc in coord_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latlon_boxes = gpd.GeoDataFrame(coord_geoms).rename(columns={0:'geometry'}).set_geometry('geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latlon_boxes['buffer_10km'] = latlon_boxes['geometry'].progress_apply(lambda el: buffer_geom(el, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['buffer_10km'] = gdf['geometry'].progress_apply(lambda el: buffer_geom(el,10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = gdf['buffer_10km'].unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(mp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_mp = gpd.GeoDataFrame(list(mp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_mp = gdf_mp.rename(columns={0:'geometry'}).set_geometry('geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(24,16))\n",
    "gdf.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_mp.to_file('./data/SPV_10km_buffer.gpkg',driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = pygeos.STRtree([pygeos.io.from_shapely(geom) for geom in gdf_mp['geometry'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = tree.query_bulk([pygeos.io.from_shapely(geom) for geom in gdf['geometry'].values], predicate='intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_mp['intersects_unique_ids'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_df = pd.DataFrame(Q.T, columns = ['SPV_idx','mp_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.loc[Q_df.iloc[(Q_df['mp_idx']==2207).values, Q_df.columns.get_loc('SPV_idx')].values,'unique_id'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(len(gdf_mp)):\n",
    "    if ii%100==0:\n",
    "        print (ii)\n",
    "    gdf_mp.iat[ii,gdf_mp.columns.get_loc('intersects_unique_ids')] = gdf.loc[Q_df.iloc[(Q_df['mp_idx']==ii).values, Q_df.columns.get_loc('SPV_idx')].values,'unique_id'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_mp['intersects_unique_ids'] = gdf_mp['intersects_unique_ids'].apply(json.dumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_mp.to_file('./data/SPV_10km_buffer.gpkg',driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_geojson(row):\n",
    "    fname = f'{row.name}_10k.geojson'\n",
    "    gj = geojson.FeatureCollection([geojson.Feature(geometry=row['geometry'], properties={'intersects_unique_ids':row['intersects_unique_ids']})])\n",
    "    json.dump(gj, open(os.path.join(os.getcwd(),'data','landmark_mp',fname),'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_mp.apply(lambda row: to_geojson(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_mp = gpd.read_file('./data/SPV_10km_buffer.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach:**\n",
    "- get pos/neg on gdf_mp\n",
    "- where there's a single id or NEG, use the results from the search and populate to gdf\n",
    "- where there are multiple ids POS, need to refine the search. -> see how many units this is for a start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_results = glob.glob('./data/landmark_results_mp/*.csv')\n",
    "rerun_results = glob.glob('./data/landmark_results_mp/rerun/*.csv')\n",
    "T_png = glob.glob('./data/landmark_results_mp/imgs/pos/*.png')\n",
    "F_png = glob.glob('./data/landmark_results_mp/imgs/neg/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(csv_results)+len(rerun_results)+len(T_png)+len(F_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_mp['P/N'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in csv_results+rerun_results:\n",
    "    if f.split('.')[-1]=='csv':\n",
    "        result = pd.read_csv(f)\n",
    "        idx = os.path.split(f)[-1].split('.')[0]\n",
    "        if len(result)>0:\n",
    "            gdf_mp.loc[int(idx),'P/N'] = 'T'\n",
    "        elif len(result)==0:\n",
    "            gdf_mp.loc[int(idx),'P/N'] = 'F'\n",
    "            \n",
    "for f in T_png:\n",
    "    idx = os.path.split(f)[-1].split('.')[0]\n",
    "    gdf_mp.loc[int(idx), 'P/N'] = 'T'\n",
    "    \n",
    "for f in F_png:\n",
    "    idx = os.path.split(f)[-1].split('.')[0]\n",
    "    gdf_mp.loc[int(idx), 'P/N'] = 'F'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun = gdf_mp[gdf_mp['P/N']==''].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_mp['intersects_unique_ids']= gdf_mp['intersects_unique_ids'].apply(lambda el: json.loads(el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_mp[(gdf_mp['P/N']=='T') & (gdf_mp['intersects_unique_ids'].str.len()>1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambig = gdf_mp.loc[(gdf_mp['P/N']=='T') & (gdf_mp['intersects_unique_ids'].str.len()>1),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in ambig.iterrows():\n",
    "    print('IDX',idx)\n",
    "    fig, ax =plt.subplots(1,1,figsize=(16,16))\n",
    "    gdf_slice = gdf.loc[gdf['unique_id'].isin(row['intersects_unique_ids']),:]\n",
    "    gdf_slice['buffer_geom'] = gdf_slice['geometry'].apply(lambda el: buffer_geom(el, 10000))\n",
    "                                                           \n",
    "    gdf_slice.set_geometry('buffer_geom').boundary.plot(ax=ax)\n",
    "    for idx2, row2 in gdf_slice.iterrows():\n",
    "        pt = row2['geometry'].representative_point()\n",
    "        ax.text(pt.x,pt.y,row2['unique_id'])\n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    rec = input('meow')\n",
    "    recs.append({idx:rec})\n",
    "    pd.DataFrame.from_records(recs).to_csv('./landmark_handlabel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hand = pd.Series(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hand.apply(lambda el: el.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hand = pd.DataFrame([r.items() for r in recs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hand['index'] = df_hand[0].str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hand['note'] = df_hand[0].str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hand.drop(columns=[0]).to_csv('./landmark_handlabel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hand = df_hand.rename(columns={'index':'mp_index'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(gdf_mp, df_hand[['mp_index','note']], how='left',left_index=True, right_on='mp_index').set_index('mp_index').drop(columns=['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ic = pd.DataFrame(df_merged).explode('intersects_unique_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ic.reset_index().set_index('intersects_unique_ids').to_csv('./data/landmark/consolidation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ic['note'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ic['note'] = df_ic['note'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_idx =   ['42482', '62324', '34025', '22303', '15993', '42637', '42665', '42045','14788', '34473', '34015', '33551', '33606', '26072', '32314', '33631', '33678', '33850', '34611', '33957', '34060', '34054', '34168', '33585', '32686', '26231, 26251', '29078', '33822', '33919',  '1107', '59347', '59341', '59392', '59306', '59366', '24268', '24428', '32562','28544']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_mapper(row):\n",
    "    if row['note']=='nan' and row['P/N']=='F':\n",
    "        return 'no results'\n",
    "    elif row['note']=='nan' and row['P/N']=='T':\n",
    "        return 'from csv'\n",
    "    elif row['note']=='all':\n",
    "        return 'from csv'\n",
    "    elif row['note']=='breakup':\n",
    "        return 'do individual'\n",
    "    elif row['note'] in ['337 - only millewa-mallee; else all.','Walpole Island Indian Reserve to 63387, all others to all']:\n",
    "        return 'from csv - custom'\n",
    "    elif 'only' in row['note']:\n",
    "        if row['intersects_unique_ids'] in only_idx:\n",
    "            return 'do individual'\n",
    "        elif 'LV intersections' in row['note']:\n",
    "            return 'geomlookup_LV'\n",
    "        else:\n",
    "            return 'no results'\n",
    "    elif row['note']=='all except 22275, 22288':\n",
    "        if row['intersects_unique_ids'] in ['22275', '22288']:\n",
    "            return 'no results'\n",
    "        else:\n",
    "            return 'from csv'\n",
    "    elif row['note']=='not 22297, 62896':\n",
    "        if row['intersects_unique_ids'] in ['22297', '62896']:\n",
    "            return 'no results'\n",
    "        else:\n",
    "            return 'from csv'\n",
    "    elif row['note']=='not 14738':\n",
    "        if row['intersects_unique_ids'] in ['14738']:\n",
    "            return 'no results'\n",
    "        else:\n",
    "            return 'from csv'\n",
    "    elif 'uk comm' in row['note'].lower():\n",
    "        return 'geomlookup_UK'\n",
    "    elif row['note']=='S of 23, E, intersecting, 120.5':\n",
    "        return 'geomlookup_SE231205'\n",
    "    elif row['note']=='intersects socal_intersections.geojson':\n",
    "        return 'geomlookup_SOCAL'\n",
    "    elif row['note']=='intersects mexico':\n",
    "        return 'geomlookup_MX'\n",
    "    elif row['note']=='breakup south of 33.2':\n",
    "        return 'geomlookup_S33.2'\n",
    "    elif row['note']=='norcal intersections.geojson':\n",
    "        return 'geomlookup_NORCAL'\n",
    "    elif row['note']=='only long island intersections':\n",
    "        return 'geomlookup_LONGISLAND'\n",
    "    elif row['note']=='only boston_intersection.geojson':\n",
    "        return 'geomlookup_BOSTON'\n",
    "    elif row['note']=='intersects Point(-75.7, 43.1)':\n",
    "        return 'geomlookup_PT75'\n",
    "    elif row['note']=='intersects Point(-79.3, 44.3':\n",
    "        return 'geomlookup_PT79'\n",
    "    elif row['note']=='intersects minneapolis_intersections.geojson':\n",
    "        return 'geomlookup_MINN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ic['map_col'] = df_ic.apply(lambda row: big_mapper(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ic.groupby('map_col').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ic = pd.read_csv('./data/landmark/consolidation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_table = {\n",
    "    'geomlookup_LV':gpd.read_file(os.path.join(os.getcwd(),'solarpv','analysis','proximity','LV_intersections.geojson')).unary_union,\n",
    "    'geomlookup_MINN':gpd.read_file(os.path.join(os.getcwd(),'solarpv','analysis','proximity','minneapolis_intersections.geojson')).unary_union,\n",
    "    'geomlookup_MX':gpd.read_file(os.path.join(os.getcwd(),'data','ne_10m_countries.gpkg')).unary_union,\n",
    "    'geomlookup_NORCAL':gpd.read_file(os.path.join(os.getcwd(),'solarpv','analysis','proximity','norcal_intersections.geojson')).unary_union,\n",
    "    'geomlookup_PT75':geometry.Point(-75.7, 43.1),\n",
    "    'geomlookup_PT79':geometry.Point(-79.3, 44.3),\n",
    "    'geomlookup_S33.2':geometry.box(-179,0,179,33.2),\n",
    "    'geomlookup_SE231205':geometry.box(120.5, 0,179,23),\n",
    "    'geomlookup_SOCAL':gpd.read_file(os.path.join(os.getcwd(),'solarpv','analysis','proximity','socal_intersections.geojson')).unary_union,\n",
    "    'geomlookup_UK':gpd.read_file(os.path.join(os.getcwd(),'solarpv','analysis','proximity','UK_communities.gdb')),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UK_communities = gpd.read_file('./solarpv/analysis/proximity/UK_communities.gdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.loc[gdf['unique_id']==68657, 'geometry'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_step(row):\n",
    "    if row['map_col'] in [kk for kk in geom_table.keys() if kk!='geomlookup_UK']:\n",
    "        ### buffer\n",
    "        orig_geom = gdf.loc[gdf['unique_id']==int(row['intersects_unique_ids']),'geometry']\n",
    "        if len(orig_geom)==0:\n",
    "            print ('missing geom bork')\n",
    "            return 'missing geom'\n",
    "        else:\n",
    "            orig_geom = orig_geom.values[0]\n",
    "        buffered_geom = buffer_geom(orig_geom,10000)\n",
    "        ### intersects\n",
    "        if buffered_geom.intersects(geom_table[row['map_col']]):\n",
    "            return 'do individual'\n",
    "        else: \n",
    "            return 'no results'\n",
    "    elif row['map_col']=='geomlookup_UK':\n",
    "        return 'do UK'\n",
    "    else:\n",
    "        return row['map_col']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ic['next_step'] = df_ic.progress_apply(lambda row: get_next_step(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ic.groupby('next_step').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ic.loc[df_ic['mp_index'].isin([1755, 1788, 1803, 1815, 1822, 1866, 3652, 1935,1938, 1977, 1981]),'next_step'] = 'do individual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(df_ic.loc[df_ic['next_step']=='do individual','intersects_unique_ids'].values.tolist(), open(os.path.join(os.getcwd(),'solarpv','analysis','proximity','do_individual.json'),'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df_ic.loc[df_ic['next_step']=='do individual',:].iterrows():\n",
    "    orig_geom = gdf.loc[gdf['unique_id']==int(row['intersects_unique_ids']),'geometry'].values[0]\n",
    "    buffered_geom = buffer_geom(orig_geom,10000)\n",
    "    gj = geojson.FeatureCollection([geojson.Feature(geometry=buffered_geom,properties={})])\n",
    "    json.dump(gj, open(os.path.join(os.getcwd(),'data','landmark','do_individual',f'{row[\"intersects_unique_ids\"]}.geojson'),'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### after that's done..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ic.loc[df_ic['note']=='Walpole Island Indian Reserve to 63387, all others to all','next_step'] = 'from csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ic['intersects_unique_ids'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ic.groupby('next_step').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## csv_dfs\n",
    "mp_csvs = glob.glob(os.path.join(os.getcwd(),'data','landmark_results_mp','*.csv'))\n",
    "individual_csvs = glob.glob(os.path.join(os.getcwd(),'data','landmark_results','do_individual','*.csv'))\n",
    "csvs = {os.path.split(f)[-1].split('.')[0]:pd.read_csv(f) for f in mp_csvs}\n",
    "csvs.update({'individual-'+os.path.split(f)[-1].split('.')[0]:pd.read_csv(f) for f in individual_csvs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_names_finally(row):\n",
    "    \n",
    "    \n",
    "    if row['next_step'] == 'no results':\n",
    "        return ['']\n",
    "    elif row['next_step'] == 'from csv':\n",
    "        if str(row['mp_index']) not in csvs.keys():\n",
    "            print('bork key!', str(row['mp_index']))\n",
    "            return ['']\n",
    "        return csvs[str(row['mp_index'])].loc[:,'name'].unique().tolist()\n",
    "    elif row['next_step'] == 'from csv - custom':\n",
    "        if row['intersects_unique_ids']==337:\n",
    "            return csvs['26-special'].loc[:,'name'].unique().tolist()\n",
    "        else:\n",
    "            if str(row['mp_index']) not in csvs.keys():\n",
    "                print('bork key!', str(row['mp_index']))\n",
    "                return ['']\n",
    "            return csvs[str(row['mp_index'])].loc[:,'name'].unique().tolist()\n",
    "    elif row['next_step'] == 'do UK':\n",
    "        orig_geom = gdf.loc[gdf['unique_id']==int(row['intersects_unique_ids']),'geometry'].values[0]\n",
    "        buffered_geom = buffer_geom(orig_geom,10000)\n",
    "        return UK_communities.loc[UK_communities.geometry.intersects(buffered_geom),'NAME'].unique().tolist()\n",
    "    elif row['next_step'] == 'do individual':\n",
    "        if str(row['mp_index']) not in csvs.keys():\n",
    "            print('bork key!', str(row['mp_index']))\n",
    "            return ['']\n",
    "        return csvs[f'individual-{row[\"intersects_unique_ids\"]}'].loc[:,'name'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ic['names'] = df_ic.progress_apply(lambda row: do_names_finally(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ic[['intersects_unique_ids','names']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_wdpa = gpd.read_file('./data/SPV_wdpa.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### merge to gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['WDPA_proximity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ic.to_csv('./data/landmark/consolidation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = pd.merge(gdf,df_ic[['intersects_unique_ids','names']], how='left',left_on='unique_id',right_on='intersects_unique_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['names'] = gdf['names'].apply(json.dumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.drop(columns=['cap_test','intersects_unique_ids','GCR','eff','ILR','lc_mode','lc_arid','lc_vis','install_date_ints']).rename(columns={'WDPA_proximity':'wdpa_10km','names':'ind_comm_10km'}).to_file('./data/SPV_v3.geojson',driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do I&C status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** rerun the missing ones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rerun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in rerun:\n",
    "    shutil.copy(f'./data/landmark_mp/{idx}_10k.geojson',f'./data/landmark_mp/rerun/{idx}_10k.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
