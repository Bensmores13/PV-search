{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojson\n",
    "import geopandas as gpd\n",
    "import pygeos\n",
    "import descarteslabs as dl\n",
    "import pandas as pd\n",
    "from shapely import geometry, wkt\n",
    "from shapely.ops import cascaded_union\n",
    "import numpy as np\n",
    "import json, os, sys\n",
    "import yaml\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from area import area\n",
    "gpd.options.use_pygeos=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.abspath(os.path.join(os.getcwd(),'..','..','..'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Combine airbus and cv polygons\n",
    "- get S2-shaped tiles for all polygons\n",
    "- filter those tiles for only those within airbus tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Test Set Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tiles = gpd.read_file(os.path.join(root,'data','testset_aois.geojson'))\n",
    "test_polys = gpd.read_file(os.path.join(root,'data','test_set_handlabelled.geojson'))\n",
    "extra_polys = gpd.read_file(os.path.join(root,'data','extra_pr_fts.geojson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polys = test_polys.append(extra_polys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get interim vetor products\n",
    "config = yaml.safe_load(open(os.path.join(root,'cloud_products_exec.yaml'),'r'))\n",
    "for kk in config.keys():\n",
    "    print (config[kk]['cloud_id'])\n",
    "vector_keys = [kk for kk in config.keys() if kk.split('-')[1][0]=='V']\n",
    "vector_keys=vector_keys[1:]\n",
    "print(vector_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tiles_mp = test_tiles.unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polys_mp = test_polys.unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download intertim features\n",
    "for kk in vector_keys:\n",
    "    fc = dl.vectors.FeatureCollection(config[kk]['cloud_id'])\n",
    "    fts = [geojson.Feature(geometry=f.geometry, properties=f.properties) for f in fc.filter(test_tiles_mp).features()]\n",
    "    print (kk, len(fts))\n",
    "    json.dump(geojson.FeatureCollection(fts),open(os.path.join(root,'data','test_data',kk+'.geojson'),'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get final product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_polys=gpd.read_file(os.path.join(root,'data','ABCD_simplified.geojson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_polys = final_polys[final_polys.intersects(test_tiles_mp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_polys.to_file(os.path.join(root,'data','test_data','compile_final.geojson'),driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load downloaded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfs = {}\n",
    "for kk in vector_keys + ['pre-handlabel']:\n",
    "    big_json = json.load(open(os.path.join(root,'data','test_data',kk+'.geojson'),'r'))\n",
    "    for ii_f,ft in enumerate(big_json['features']):\n",
    "        ft['properties'] = {}\n",
    "    gdfs[kk] = gpd.GeoDataFrame.from_features(big_json['features'])\n",
    "    gdfs[kk] = gdfs[kk].set_crs('epsg:4326')\n",
    "    print (kk)\n",
    "gdfs['compiled_final']=gpd.read_file(os.path.join(root,'data','test_data','compile_final.geojson'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make sure pre-handlabel is intersecting SPOT-V2 or S2-V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_geoms = [pygeos.io.from_shapely(geom) for geom in gdfs['S2-V4-Final']['geometry'].values] + [pygeos.io.from_shapely(geom) for geom in gdfs['SPOT-V2-Filtered']['geometry'].values]\n",
    "intersect_tree = pygeos.STRtree(pg_geoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = intersect_tree.query_bulk([pygeos.io.from_shapely(geom) for geom in gdfs['pre-handlabel']['geometry'].values], predicate='intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfs['pre-handlabel'] = gdfs['pre-handlabel'].loc[gdfs['pre-handlabel'].index.isin(np.unique(Q[0,:])),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfs['pre-handlabel'].to_file(os.path.join(root,'data','prehandlabel_filtered.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tiles['geoarea'] = test_tiles['geometry'].apply(lambda el: area(geometry.mapping(el)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polys['geoarea'] = test_polys['geometry'].apply(lambda el: area(geometry.mapping(el)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kk in gdfs.keys():\n",
    "    gdfs[kk]['geoarea'] = gdfs[kk]['geometry'].apply(lambda el: area(geometry.mapping(el)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some filters on S2: >30m^2; cascade-union-reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(gdfs['pre-handlabel']['geoarea']).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.histogram(np.log10(gdfs['S2-V2-Secondary']['geoarea']), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (list(zip(10**res[1],res[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['S2-V1-Primary','S2-V2-Secondary', 'S2-V3-Deepstack', 'S2-V4-Final']:\n",
    "    gdfs[key] = gdfs[key][gdfs[key]['geoarea']>30]\n",
    "    mp = cascaded_union( gdfs[key].geometry.values)\n",
    "    print (key, len(list(mp)))\n",
    "    gdfs[key] = gpd.GeoDataFrame(geometry=list(mp), crs={'init': 'epsg:4326'})\n",
    "    gdfs[key]['geoarea'] = gdfs[key].to_crs({'init': 'epsg:3857'}).area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision / recall - full areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# area-binned object level recall -> bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_bins = [30,1e2,1e3,1e4,1e5,1e6,1e10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict= {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tree = pygeos.STRtree([pygeos.io.from_shapely(geom) for geom in test_polys['geometry'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for kk,gdf in gdfs.items():\n",
    "    res_dict[kk] = {}\n",
    "    #pipe_mp = gdf.unary_union\n",
    "    gdf_tree = pygeos.STRtree([pygeos.io.from_shapely(geom) for geom in gdf['geometry'].values])\n",
    "    for ii_a in range(len(area_bins)-1):\n",
    "        res_dict[kk][ii_a] = {}\n",
    "        # precision = TP/(TP+FP)\n",
    "        # query the test set with the area slice\n",
    "        \n",
    "        bin_slice = gdf[(gdf.geoarea>=area_bins[ii_a]) & (gdf.geoarea<area_bins[ii_a+1])]\n",
    "        if len(bin_slice)>0:\n",
    "            Q = test_tree.query_bulk([pygeos.io.from_shapely(geom) for geom in bin_slice['geometry'].values], predicate='intersects')\n",
    "            intersects = np.isin(np.arange(len(bin_slice)), np.unique(Q[0,:]))\n",
    "            TP = np.sum(intersects)\n",
    "            FP = np.sum(~intersects)\n",
    "            res_dict[kk][ii_a]['P']=TP/(TP+FP)\n",
    "            res_dict[kk][ii_a]['P_TP'] = TP\n",
    "            res_dict[kk][ii_a]['P_FP'] = FP\n",
    "        else:\n",
    "            # no detections in that size\n",
    "            res_dict[kk][ii_a]['P']=np.nan\n",
    "            res_dict[kk][ii_a]['P_TP'] = 0\n",
    "            res_dict[kk][ii_a]['P_FP'] = 0\n",
    "        \n",
    "        # recall = TP / (TP+FN)\n",
    "        test_slice = test_polys[(test_polys.geoarea>=area_bins[ii_a])&(test_polys.geoarea<area_bins[ii_a+1])]\n",
    "        Q = gdf_tree.query_bulk([pygeos.io.from_shapely(geom) for geom in test_slice['geometry'].values], predicate='intersects')\n",
    "        intersects = np.isin(np.arange(len(test_slice)), np.unique(Q[0,:]))\n",
    "        TP = np.sum(intersects)\n",
    "        FN = np.sum(~intersects)\n",
    "        res_dict[kk][ii_a]['R']=TP/(TP+FN)\n",
    "        res_dict[kk][ii_a]['R_TP'] = TP\n",
    "        res_dict[kk][ii_a]['R_FN'] = FN\n",
    "        \n",
    "        \n",
    "        print (kk,area_bins[ii_a],res_dict[kk][ii_a])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(res_dict, open(os.path.join(root,'data','test_data','res_dict_all.pickle'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crs ={'init': 'epsg:4326'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IOU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iou\n",
    "iou_dict = {}\n",
    "for kk,gdf in gdfs.items():\n",
    "    iou_dict[kk] = {}\n",
    "    \n",
    "    gdf['component_idx'] = np.nan\n",
    "    \n",
    "    # make the gdf tree\n",
    "    gdf_tree = pygeos.STRtree([pygeos.io.from_shapely(geom) for geom in gdf['geometry'].values])\n",
    "    \n",
    "    # get the intersection groups with the full test set and create the adjacency graph\n",
    "    Q = gdf_tree.query_bulk([pygeos.io.from_shapely(geom) for geom in test_polys['geometry'].values], predicate='intersects')\n",
    "    G = nx.Graph()\n",
    "    edges = [(f'test_{a}',f'pipe_{b}') for a,b in zip(Q[0,:],Q[1,:])]\n",
    "    G.add_edges_from(edges)\n",
    "    \n",
    "    # use the connected components to map intersection on to the test set df\n",
    "    print (kk, 'doing prep...')\n",
    "    test_polys['intersection_geom'] = ''\n",
    "    test_polys['union_area'] = np.nan\n",
    "    test_polys['area_portion'] = np.nan\n",
    "    for ii_g, g in enumerate(nx.connected_components(G)):\n",
    "        test_idxs = [int(stridx.split('_')[1]) for stridx in list(g) if 'test' in stridx]\n",
    "        pipe_idxs = [int(stridx.split('_')[1]) for stridx in list(g) if 'pipe' in stridx]\n",
    "        \n",
    "        # mark the component on the gdf\n",
    "        gdf.iloc[pipe_idxs,gdf.columns.get_loc('component_idx')] = ii_g\n",
    "\n",
    "        for idx in test_idxs:\n",
    "            mp = gdf.iloc[pipe_idxs,:].unary_union\n",
    "            geom_intersection = mp.intersection(test_polys.iloc[idx,test_polys.columns.get_loc('geometry')].buffer(0))\n",
    "            test_polys.iloc[idx,test_polys.columns.get_loc('intersection_geom')] = geom_intersection.wkt\n",
    "\n",
    "        # also map total component union area and portion of component area\n",
    "        test_mp = test_polys.iloc[test_idxs,:].unary_union\n",
    "        test_mp_area = area(geometry.mapping(test_mp))\n",
    "        test_polys.iloc[test_idxs,test_polys.columns.get_loc('union_area')] = area(geometry.mapping(gdf.iloc[pipe_idxs,:].unary_union))\n",
    "        test_polys.iloc[test_idxs,test_polys.columns.get_loc('area_portion')] = test_polys.iloc[test_idxs,:].apply(lambda row: area(geometry.mapping(row['geometry']))/test_mp_area, axis=1)\n",
    "    \n",
    "    test_polys['intersection_area'] = test_polys['intersection_geom'].apply(lambda el: area(geometry.mapping(wkt.loads(el))) if not el=='' else 0)\n",
    "    test_polys['specific_union_area'] = test_polys['area_portion'] * test_polys['union_area']\n",
    "\n",
    "    \n",
    "    for ii_a in range(len(area_bins)-1):\n",
    "        \n",
    "        iou_dict[kk][ii_a] = {}\n",
    "        \n",
    "        # then, for each area bin:\n",
    "        ## sum the intersections -> intersection\n",
    "        ## sum the componnet unions * the portion of component area\n",
    "        ## ... and add any non-component geoms from the gdf -> union\n",
    "        \n",
    "        gross_intersection_area = test_polys.loc[(test_polys.geoarea>=area_bins[ii_a])&(test_polys.geoarea<area_bins[ii_a+1]), 'intersection_area'].sum()\n",
    "        \n",
    "        gross_union_area = test_polys.loc[(test_polys.geoarea>=area_bins[ii_a])&(test_polys.geoarea<area_bins[ii_a+1]), 'specific_union_area'].sum()\n",
    "        gross_union_area = gross_union_area + gdf.loc[(gdf['component_idx'].isna()) & (gdf.geoarea>=area_bins[ii_a])&(gdf.geoarea<area_bins[ii_a+1]),'geoarea'].sum()\n",
    "    \n",
    "        \n",
    "        iou_dict[kk][ii_a]['i'] = gross_intersection_area\n",
    "        iou_dict[kk][ii_a]['u'] = gross_union_area\n",
    "        iou_dict[kk][ii_a]['iou'] = gross_intersection_area / gross_union_area\n",
    "        \n",
    "        print (ii_a,iou_dict[kk][ii_a])\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(iou_dict, open('./iou_dict_all.pickle','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polys['area_error'] =  test_polys['specific_union_area'] / test_polys['geoarea'] - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_dict = {}\n",
    "fig, axs = plt.subplots(1,len(area_bins)-1,figsize=(15,3))\n",
    "\n",
    "for ii_a in range(len(area_bins)-1):\n",
    "    axs[ii_a].hist(test_polys.loc[(test_polys.geoarea>=area_bins[ii_a])&(test_polys.geoarea<area_bins[ii_a+1]), 'area_error'], bins=30)\n",
    "    mu, sigma = norm.fit(test_polys.loc[(test_polys.geoarea>=area_bins[ii_a])&(test_polys.geoarea<area_bins[ii_a+1])&(~test_polys['area_error'].isna()), 'area_error'].values)\n",
    "    N = test_polys.loc[(test_polys.geoarea>=area_bins[ii_a])&(test_polys.geoarea<area_bins[ii_a+1])&(~test_polys['area_error'].isna()), 'area_error'].size\n",
    "    area_dict[ii_a] = {'ii_a':ii_a,'mu':mu,'sigma':sigma,'N':N}\n",
    "    \n",
    "    print (ii_a,mu, sigma,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(area_dict, open('./area_dict.pickle','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision/recall/iou - two areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_bins = [1e4, 1e10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict= {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tree = pygeos.STRtree([pygeos.io.from_shapely(geom) for geom in test_polys['geometry'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kk,gdf in gdfs.items():\n",
    "    res_dict[kk] = {}\n",
    "    #pipe_mp = gdf.unary_union\n",
    "    gdf_tree = pygeos.STRtree([pygeos.io.from_shapely(geom) for geom in gdf['geometry'].values])\n",
    "    for ii_a in range(len(area_bins)-1):\n",
    "        res_dict[kk][ii_a] = {}\n",
    "        # precision = TP/(TP+FP)\n",
    "        # query the test set with the area slice\n",
    "        \n",
    "        bin_slice = gdf[(gdf.geoarea>=area_bins[ii_a]) & (gdf.geoarea<area_bins[ii_a+1])]\n",
    "        if len(bin_slice)>0:\n",
    "            Q = test_tree.query_bulk([pygeos.io.from_shapely(geom) for geom in bin_slice['geometry'].values], predicate='intersects')\n",
    "            intersects = np.isin(np.arange(len(bin_slice)), np.unique(Q[0,:]))\n",
    "            TP = np.sum(intersects)\n",
    "            FP = np.sum(~intersects)\n",
    "            res_dict[kk][ii_a]['P']=TP/(TP+FP)\n",
    "            res_dict[kk][ii_a]['P_TP'] = TP\n",
    "            res_dict[kk][ii_a]['P_FP'] = FP\n",
    "        else:\n",
    "            # no detections in that size\n",
    "            res_dict[kk][ii_a]['P']=np.nan\n",
    "            res_dict[kk][ii_a]['P_TP'] = 0\n",
    "            res_dict[kk][ii_a]['P_FP'] = 0\n",
    "        \n",
    "        # recall = TP / (TP+FN)\n",
    "        test_slice = test_polys[(test_polys.geoarea>=area_bins[ii_a])&(test_polys.geoarea<area_bins[ii_a+1])]\n",
    "        Q = gdf_tree.query_bulk([pygeos.io.from_shapely(geom) for geom in test_slice['geometry'].values], predicate='intersects')\n",
    "        intersects = np.isin(np.arange(len(test_slice)), np.unique(Q[0,:]))\n",
    "        TP = np.sum(intersects)\n",
    "        FN = np.sum(~intersects)\n",
    "        res_dict[kk][ii_a]['R']=TP/(TP+FN)\n",
    "        res_dict[kk][ii_a]['R_TP'] = TP\n",
    "        res_dict[kk][ii_a]['R_FN'] = FN\n",
    "        \n",
    "        \n",
    "        print (kk,area_bins[ii_a],res_dict[kk][ii_a])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(res_dict,open('./res_dict_10k.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iou\n",
    "iou_dict = {}\n",
    "for kk,gdf in gdfs.items():\n",
    "    iou_dict[kk] = {}\n",
    "    \n",
    "    gdf['component_idx'] = np.nan\n",
    "    \n",
    "    # make the gdf tree\n",
    "    gdf_tree = pygeos.STRtree([pygeos.io.from_shapely(geom) for geom in gdf['geometry'].values])\n",
    "    \n",
    "    # get the intersection groups with the full test set and create the adjacency graph\n",
    "    Q = gdf_tree.query_bulk([pygeos.io.from_shapely(geom) for geom in test_polys['geometry'].values], predicate='intersects')\n",
    "    G = nx.Graph()\n",
    "    edges = [(f'test_{a}',f'pipe_{b}') for a,b in zip(Q[0,:],Q[1,:])]\n",
    "    G.add_edges_from(edges)\n",
    "    \n",
    "    # use the connected components to map intersection on to the test set df\n",
    "    print (kk, 'doing prep...')\n",
    "    test_polys['intersection_geom'] = ''\n",
    "    test_polys['union_area'] = np.nan\n",
    "    test_polys['area_portion'] = np.nan\n",
    "    for ii_g, g in enumerate(nx.connected_components(G)):\n",
    "        test_idxs = [int(stridx.split('_')[1]) for stridx in list(g) if 'test' in stridx]\n",
    "        pipe_idxs = [int(stridx.split('_')[1]) for stridx in list(g) if 'pipe' in stridx]\n",
    "        \n",
    "        # mark the component on the gdf\n",
    "        gdf.iloc[pipe_idxs,gdf.columns.get_loc('component_idx')] = ii_g\n",
    "\n",
    "        for idx in test_idxs:\n",
    "            mp = gdf.iloc[pipe_idxs,:].unary_union\n",
    "            geom_intersection = mp.intersection(test_polys.iloc[idx,test_polys.columns.get_loc('geometry')].buffer(0))\n",
    "            test_polys.iloc[idx,test_polys.columns.get_loc('intersection_geom')] = geom_intersection.wkt\n",
    "\n",
    "        # also map total component union area and portion of component area\n",
    "        test_mp = test_polys.iloc[test_idxs,:].unary_union\n",
    "        test_mp_area = area(geometry.mapping(test_mp))\n",
    "        test_polys.iloc[test_idxs,test_polys.columns.get_loc('union_area')] = area(geometry.mapping(gdf.iloc[pipe_idxs,:].unary_union))\n",
    "        test_polys.iloc[test_idxs,test_polys.columns.get_loc('area_portion')] = test_polys.iloc[test_idxs,:].apply(lambda row: area(geometry.mapping(row['geometry']))/test_mp_area, axis=1)\n",
    "    \n",
    "    test_polys['intersection_area'] = test_polys['intersection_geom'].apply(lambda el: area(geometry.mapping(wkt.loads(el))) if not el=='' else 0)\n",
    "    test_polys['specific_union_area'] = test_polys['area_portion'] * test_polys['union_area']\n",
    "\n",
    "    \n",
    "    for ii_a in range(len(area_bins)-1):\n",
    "        \n",
    "        iou_dict[kk][ii_a] = {}\n",
    "        \n",
    "        # then, for each area bin:\n",
    "        ## sum the intersections -> intersection\n",
    "        ## sum the componnet unions * the portion of component area\n",
    "        ## ... and add any non-component geoms from the gdf -> union\n",
    "        \n",
    "        gross_intersection_area = test_polys.loc[(test_polys.geoarea>=area_bins[ii_a])&(test_polys.geoarea<area_bins[ii_a+1]), 'intersection_area'].sum()\n",
    "        \n",
    "        gross_union_area = test_polys.loc[(test_polys.geoarea>=area_bins[ii_a])&(test_polys.geoarea<area_bins[ii_a+1]), 'specific_union_area'].sum()\n",
    "        gross_union_area = gross_union_area + gdf.loc[(gdf['component_idx'].isna()) & (gdf.geoarea>=area_bins[ii_a])&(gdf.geoarea<area_bins[ii_a+1]),'geoarea'].sum()\n",
    "    \n",
    "        \n",
    "        iou_dict[kk][ii_a]['i'] = gross_intersection_area\n",
    "        iou_dict[kk][ii_a]['u'] = gross_union_area\n",
    "        iou_dict[kk][ii_a]['iou'] = gross_intersection_area / gross_union_area\n",
    "        \n",
    "        print (ii_a,iou_dict[kk][ii_a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(iou_dict, open('./iou_dict_10k.pickle','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = pickle.load(open('./res_dict_2020-04-07.pkl','rb'))# open('../../data/res_dict.pkl','rb'))\n",
    "iou_dict = pickle.load(open('./iou_dict_2020-04-07.pickle','rb'))# open('../../data/iou_dict.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, vv in res_dict.items():\n",
    "    for ar,vv2 in vv.items():\n",
    "        vv2['iou'] = iou_dict[key][ar]['iou']\n",
    "        vv2['iou_neg'] = iou_dict[key][ar]['iou_neg']\n",
    "        #vv2['iou_pos'] = iou_dict[key][ar]['iou_pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.collections import LineCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_dict = {'P':'Precision','R':'Recall','iou_neg':'Intersection-over-Union'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex2rgb(h):\n",
    "    h = h.lstrip('#')\n",
    "    return [int(h[i:i+2], 16) for i in (0, 2, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg_colors = [tuple(ih/255 for ih in hex2rgb(ii['color'])) for ii in list(plt.rcParams['axes.prop_cycle'])[0:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(area_bins)-1,3,figsize=(40,20),sharey=True, sharex=True)\n",
    "# plot P\n",
    "for ii_a in range(len(area_bins)-1):\n",
    "    \n",
    "    for ii_ax, M in enumerate(['P','R','iou_neg']):\n",
    "        full_bars= [res_dict[kk][ii_a][M] for kk in gdfs.keys()] \n",
    "\n",
    "        bars = [full_bars[0]] + \\\n",
    "            [(full_bars[ii] - full_bars[ii-1]) for ii in range(1,4)] + \\\n",
    "            [full_bars[4], full_bars[5]-full_bars[4]] +\\\n",
    "            [full_bars[6]]\n",
    "        bottoms = [0]+\\\n",
    "                    [full_bars[ii-1] for ii in range(1,4)] +\\\n",
    "                    [0,full_bars[4],0]\n",
    "        \n",
    "        lines_y = [el for el in full_bars for _ in (0,1)]\n",
    "        lines_x = [0] + [el for el in range(1,6) for _ in (0,1)] + [6]\n",
    "        segs = [[[lines_x[ii], lines_y[ii]],[lines_x[ii+1],lines_y[ii+1]]] for ii in range(0,12,2)]\n",
    "        \n",
    "        segs[3][1][0]=3.5\n",
    "        segs[5][1][0]=5.5\n",
    "        segs.append([segs[3][1],[segs[3][1][0],full_bars[6]]])\n",
    "        segs.append([[segs[3][1][0],full_bars[6]],[6,full_bars[6]]])\n",
    "        segs.append([segs[5][1],[segs[5][1][0],full_bars[6]]])\n",
    "        \n",
    "        \n",
    "        line_segments = LineCollection(segs, colors=[gg_colors[0]]*4 + [gg_colors[1]]*2 + [gg_colors[2]]*3, alpha=0.5)\n",
    "        axs[ii_a,ii_ax].add_collection(line_segments)\n",
    "\n",
    "        colors = [gg_colors[0]]*4 + [gg_colors[1]]*2 + [gg_colors[2]]\n",
    "\n",
    "\n",
    "        axs[ii_a,ii_ax].bar(range(len(gdfs.keys())),bars, bottom=bottoms, edgecolor=colors, linewidth=2,color=colors)\n",
    "        \n",
    "        for ii in range(7):\n",
    "            H=0.05\n",
    "            if ((M=='R' and ii_a==0) or (M=='iou_neg' and ii_a)):\n",
    "                H=.1\n",
    "                \n",
    "            axs[ii_a,ii_ax].text(ii,H,f'{full_bars[ii]:.0%}', horizontalalignment='center')\n",
    "\n",
    "        \n",
    "        axs[ii_a,ii_ax].set_xticklabels(['','S1-V1','S1-V2','S1-V3','S1-V4','SPOT-V1','SPOT-V2','Final'])\n",
    "        \n",
    "        if ii_a==0:\n",
    "            axs[ii_a,ii_ax].set_title(title_dict[M],fontsize=24)\n",
    "            axs[ii_a,ii_ax].set_ylim([0,1])\n",
    "        \n",
    "    axs[ii_a,0].set_ylabel(f'{area_bins[ii_a]:,.0f} to {area_bins[ii_a+1]:,.0f} m$^2$')\n",
    "    \n",
    "fig.savefig('../analysis/P-R-iou.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single measure 10k+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = pickle.load(open(os.path.join(root,'data','res_dict_gt10k.pickle'),'rb'))# open('../../data/res_dict.pkl','rb'))\n",
    "iou_dict = pickle.load(open(os.path.join(root,'data','iou_dict_gt10k.pickle'),'rb'))# open('../../data/iou_dict.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, vv in res_dict.items():\n",
    "    for ar,vv2 in vv.items():\n",
    "        vv2['iou'] = iou_dict[key][ar]['iou']\n",
    "        vv2['iou_neg'] = iou_dict[key][ar]['iou_neg']\n",
    "        #vv2['iou_pos'] = iou_dict[key][ar]['iou_pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict['compiled_final'][0]['P']=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_dict = {'P':'Precision','R':'Recall','iou_neg':'Intersection-over-Union'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex2rgb(h):\n",
    "    h = h.lstrip('#')\n",
    "    return [int(h[i:i+2], 16) for i in (0, 2, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg_colors = [tuple(ih/255 for ih in hex2rgb(ii['color'])) for ii in list(plt.rcParams['axes.prop_cycle'])[0:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_bins = [1e4, 1e10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(area_bins)-1,3,figsize=(18,4),sharey=True, sharex=True)\n",
    "axs = axs.reshape((1,-1))\n",
    "# plot P\n",
    "for ii_a in range(len(area_bins)-1):\n",
    "    \n",
    "    for ii_ax, M in enumerate(['P','R','iou_neg']):\n",
    "        full_bars= [res_dict[kk][ii_a][M] for kk in res_dict.keys()] \n",
    "\n",
    "        bars = [full_bars[0]] + \\\n",
    "            [(full_bars[ii] - full_bars[ii-1]) for ii in range(1,4)] + \\\n",
    "            [full_bars[4], full_bars[5]-full_bars[4]] +\\\n",
    "            [full_bars[6]]\n",
    "        bottoms = [0]+\\\n",
    "                    [full_bars[ii-1] for ii in range(1,4)] +\\\n",
    "                    [0,full_bars[4],0]\n",
    "        \n",
    "        lines_y = [el for el in full_bars for _ in (0,1)]\n",
    "        lines_x = [0] + [el for el in range(1,6) for _ in (0,1)] + [6]\n",
    "        segs = [[[lines_x[ii], lines_y[ii]],[lines_x[ii+1],lines_y[ii+1]]] for ii in range(0,12,2)]\n",
    "        \n",
    "        segs[3][1][0]=3.5\n",
    "        segs[5][1][0]=5.5\n",
    "        segs.append([segs[3][1],[segs[3][1][0],full_bars[6]]])\n",
    "        segs.append([[segs[3][1][0],full_bars[6]],[6,full_bars[6]]])\n",
    "        segs.append([segs[5][1],[segs[5][1][0],full_bars[6]]])\n",
    "        \n",
    "        \n",
    "        line_segments = LineCollection(segs, colors=[gg_colors[0]]*4 + [gg_colors[1]]*2 + [gg_colors[2]]*3, alpha=0.5)\n",
    "        axs[ii_a,ii_ax].add_collection(line_segments)\n",
    "\n",
    "        colors = [gg_colors[0]]*4 + [gg_colors[1]]*2 + [gg_colors[2]]\n",
    "\n",
    "\n",
    "        axs[ii_a,ii_ax].bar(range(len(res_dict.keys())),bars, bottom=bottoms, edgecolor=colors, linewidth=2,color=colors)\n",
    "        \n",
    "        for ii in range(7):\n",
    "            H=0.05\n",
    "            if ((M=='R' and ii_a==0) or (M=='iou_neg' and ii_a)):\n",
    "                H=.1\n",
    "                \n",
    "            axs[ii_a,ii_ax].text(ii,H,f'{full_bars[ii]:.0%}', horizontalalignment='center')\n",
    "\n",
    "        \n",
    "        axs[ii_a,ii_ax].set_xticklabels(['','S1-V1','S1-V2','S1-V3','S1-V4','SPOT-V1','SPOT-V2','Final'])\n",
    "        \n",
    "        if ii_a==0:\n",
    "            axs[ii_a,ii_ax].set_title(title_dict[M],fontsize=24)\n",
    "            axs[ii_a,ii_ax].set_ylim([0,1])\n",
    "            \n",
    "\n",
    "\n",
    "    axs[ii_a,0].yaxis.set_major_formatter(mtick.PercentFormatter(1))\n",
    "        \n",
    "    #axs[ii_a,0].set_ylabel(f'Installation area > 10,000m$^2$')\n",
    "    \n",
    "fig.savefig(os.path.join(root,'makefigs','P-R-iou_single.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dDEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_tiles = gpd.read_file(os.path.join(root,'data','cv_all_tiles.geojson'))\n",
    "cv_polys = gpd.read_file(os.path.join(root,'data','cv_all_polys.geojson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_polys_mp = geometry.MultiPolygon([geom for geom in cv_polys.unary_union.geoms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_tiles_mp =geometry.MultiPolygon([geom for geom in cv_tiles.unary_union.geoms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(os.path.join(root,'data','ABCD_finalized.geojson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_cv = gdf[gdf.intersects(cv_tiles_mp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_cv.to_file(os.path.join(root,'gdf_cv.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gdf_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cv_polys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download pipeline interim features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.safe_load(open('../../cloud_products_exec.yaml','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kk in config.keys():\n",
    "    print (config[kk]['cloud_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_keys = [kk for kk in config.keys() if kk.split('-')[1][0]=='V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_keys=vector_keys[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kk in vector_keys:\n",
    "    fc = dl.vectors.FeatureCollection(config[kk]['cloud_id'])\n",
    "    fts = [geojson.Feature(geometry=f.geometry, properties=f.properties) for f in fc.filter(cv_tiles_mp).features()]\n",
    "    print (kk, len(fts))\n",
    "    json.dump(geojson.FeatureCollection(fts),open('../data/crossvalidation/'+kk+'.geojson','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # iou = intersection / union\n",
    "        bindf_slice = gdf[(gdf.geoarea>=area_bins[ii_a]) & (gdf.geoarea<area_bins[ii_a+1])]\n",
    "        bindf_mp = bindf_slice.unary_union\n",
    "        test_slice = \n",
    "        test_mp = test_slice.unary_union\n",
    "        \n",
    "        intersection=bindf_mp.intersection(test_mp)\n",
    "        union=bindf_mp.union(test_mp)\n",
    "        \n",
    "\n",
    "        if not intersection.is_empty:\n",
    "            #print (intersection)\n",
    "        \n",
    "            if intersection.type=='Polygon':\n",
    "                \n",
    "                i_gdf = gpd.GeoDataFrame(geometry=[intersection], crs=crs)\n",
    "            else:\n",
    "                i_gdf = gpd.GeoDataFrame(geometry=list(intersection), crs=crs)\n",
    "\n",
    "            if union.type=='Polygon':\n",
    "                u_gdf = gpd.GeoDataFrame(geometry=list(union), crs=crs)\n",
    "            else:\n",
    "                u_gdf = gpd.GeoDataFrame(geometry=list(union), crs=crs)\n",
    "\n",
    "            i_gdf['geoarea'] = i_gdf.to_crs({'init': 'epsg:3857'}).area\n",
    "            u_gdf['geoarea'] = u_gdf.to_crs({'init': 'epsg:3857'}).area\n",
    "\n",
    "            iou_dict[kk][ii_a]['iou'] = i_gdf['geoarea'].sum() / u_gdf['geoarea'].sum()\n",
    "            \n",
    "        else:\n",
    "            iou_dict[kk][ii_a]['iou'] = 0\n",
    "        \n",
    "        \n",
    "        print (kk,area_bins[ii_a],iou_dict[kk][ii_a])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
