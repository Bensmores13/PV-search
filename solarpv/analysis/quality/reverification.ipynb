{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "gpd.options.use_pygeos=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, io\n",
    "from shapely import geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from area import area\n",
    "import requests\n",
    "from functools import partial\n",
    "from shapely.ops import transform,linemerge, unary_union, polygonize\n",
    "from shapely.affinity import affine_transform\n",
    "from functools import partial\n",
    "import pyproj\n",
    "\n",
    "from PIL import Image\n",
    "import descarteslabs as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.abspath(os.path.join(os.getcwd(),'..','..','..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solarpv.utils import V_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = 'AIzaSyCqfsBqzBymn_AuxGpgcG0ZajdljFdnm7c'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_poly(ft_poly,mmpix):\n",
    "\n",
    "    #V_inv -> lat,lon\n",
    "    #for each point, go centroid->pt\n",
    "    #print(centroid)\n",
    "    img_coords = []\n",
    "    for pt in list(ft_poly.exterior.coords):\n",
    "        #pt->lon,lat\n",
    "        #centroid->lon,lat\n",
    "        dist, angle, dummy = V_inv((ft_poly.centroid.y,ft_poly.centroid.x),(pt[1],pt[0]))\n",
    "        dist=dist*1000\n",
    "        #print ((400+2*(dist/mmpix*np.cos(2.*np.pi*(angle)/360.)),400+2*(dist/mmpix*np.sin(2*np.pi*angle/360.))))\n",
    "        img_coords.append((400+2*(dist/mmpix*np.cos(2.*np.pi*(angle-90.)/360.)),400+2*(dist/mmpix*np.sin(2*np.pi*(angle-90.)/360.))))\n",
    "    #V_inv(point1, point2\n",
    "    #v_dir\n",
    "    return img_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lonlat2pixXY(pt,dt):\n",
    "    lon = pt[0]\n",
    "    lat = pt[1]\n",
    "    Y = (lat-dt[3]-dt[4]/dt[1]*(lon-dt[0]))/(dt[5]-dt[2]*dt[4]/dt[1])\n",
    "    #print Y\n",
    "    X = (lon-dt[0]-Y*dt[2])/dt[1]\n",
    "    #print (lon,dt[0],X)\n",
    "    #print X\n",
    "    return [int(X),int(Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_sample(row,src = 'google'):\n",
    "    \n",
    "    ft_shp = row['geometry']\n",
    "    if ft_shp.type=='MultiPolygon':\n",
    "        run_polys = list(ft_shp)\n",
    "    else:\n",
    "        run_polys = [ft_shp]\n",
    "        \n",
    "    for ii_p,ft_poly in enumerate(run_polys):\n",
    "        centroid = ft_poly.centroid ##lon,lat\n",
    "        print ('centroid',centroid)\n",
    "        ft_bbox = ft_poly.bounds\n",
    "        \n",
    "        Dx = ft_poly.bounds[2]-ft_poly.bounds[0]\n",
    "        Dy = ft_poly.bounds[3]-ft_poly.bounds[1]\n",
    "        print (max(abs(Dx),abs(Dy)))\n",
    "        ft_box = geometry.box(*ft_poly.buffer(max(abs(Dx),abs(Dy))).bounds)\n",
    "        \n",
    "        \n",
    "        fig, axs=plt.subplots(1,2,figsize=(24,12))\n",
    "\n",
    "        if src=='google':\n",
    "            box_sides = (V_inv((ft_bbox[1],ft_bbox[0]),(ft_bbox[1],ft_bbox[2]))[0]*1000,\n",
    "                             V_inv((ft_bbox[1],ft_bbox[0]),(ft_bbox[3],ft_bbox[0]))[0]*1000)\n",
    "            #print (box_sides)\n",
    "            side_len = np.ceil(max(box_sides))\n",
    "            print ('side_len (m)',side_len)\n",
    "\n",
    "            zoom_dict = dict(zip(range(1,21),[156543.03392 * np.cos(centroid.xy[1][0] * np.pi / 180) / np.power(2, z) for z in range(1,21)]))\n",
    "            #print (zoom_dict) ##<-- METERS PER PIX, not side length\n",
    "\n",
    "            zoom = np.max(np.argwhere(np.array([(zoom_dict[k]*400-max(box_sides)) for k in range(1,21)])>0.))+1\n",
    "\n",
    "\n",
    "            #min(zoom_dict.keys(), key=(lambda k: (zoom_dict[k]-max(box_sides))))\n",
    "            print ('zoom',zoom, zoom_dict[zoom], 'area',area(geometry.mapping(row['geometry'])), np.array(centroid))\n",
    "            pix_poly = img_poly(ft_poly,zoom_dict[zoom])\n",
    "\n",
    "            urlstr = ''.join([\"\"\"https://maps.googleapis.com/maps/api/staticmap?center=\"\"\",\n",
    "                        str(centroid.xy[1][0])+\"\"\",\"\"\"+str(centroid.xy[0][0]),\n",
    "                        \"\"\"&zoom=\"\"\"+str(zoom),\n",
    "                        \"\"\"&size=400x400&scale=2&maptype=satellite&format=png&key=\"\"\", str(API_KEY)])\n",
    "\n",
    "            r = requests.get(urlstr, allow_redirects=True)\n",
    "            #print (r.content)\n",
    "\n",
    "            image_data = r.content\n",
    "            image = Image.open(io.BytesIO(image_data))\n",
    "            image = image.convert('RGB')\n",
    "\n",
    "            arr = np.asarray(image)\n",
    "            \n",
    "            axs[0].imshow(arr)\n",
    "            xs, ys = geometry.Polygon(pix_poly).exterior.xy\n",
    "            #print (geometry.Polygon(pix_poly))\n",
    "            #print (xs,ys)\n",
    "            axs[0].plot(xs,ys, color='c', linewidth=2.)\n",
    "            axs[0].set_title('Google Basemap (indeterminate date), {:.2f}m/px'.format(zoom_dict[zoom]), fontsize=20)\n",
    "        \n",
    "            \n",
    "        elif src=='SPOT':\n",
    "            scenes, ctx = dl.scenes.search(\n",
    "            ft_box,\n",
    "            products=['airbus:oneatlas:spot:v2'],\n",
    "            start_datetime='2015-09-01',  end_datetime='2018-12-31', cloud_fraction=0.2, limit=10, processing_level='surface'\n",
    "            )\n",
    "            scenes = sorted(scenes, key=lambda k: k.properties.date, reverse=True)\n",
    "            print ([s.properties.date for s in scenes])\n",
    "            \n",
    "            arr_SPOT = scenes[0].ndarray(\"red green blue\", ctx)\n",
    "\n",
    "            for s in scenes[1:]:\n",
    "                fill_por = np.sum(arr_SPOT>0)/np.prod([*arr_SPOT.shape])\n",
    "                #print (fill_por, np.sum(arr_S2), np.prod([*arr_S2.shape]))\n",
    "                new_arr = s.ndarray(\"red green blue\", ctx)\n",
    "                #print ('shapes',new_arr.shape, np.sum(new_arr>0))\n",
    "\n",
    "                arr_SPOT[new_arr.mask==False]=new_arr.data[new_arr.mask==False]\n",
    "\n",
    "\n",
    "            scene_crs = scenes[0].properties['crs']\n",
    "            dt = scenes[0].properties['geotrans']\n",
    "            dt_shapely = [dt[1],dt[2],dt[4],dt[5],dt[0],dt[3]]\n",
    "\n",
    "            WGS84 = \"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\"\n",
    "\n",
    "            wgs_proj = pyproj.Proj(WGS84)\n",
    "            utm_proj = pyproj.Proj(\"+init=\"+scene_crs, preserve_units=True)\n",
    "\n",
    "\n",
    "            dt[0] = utm_proj(*ctx.bounds[0:2])[0]\n",
    "            dt[3] = utm_proj(*ctx.bounds[2:])[1]\n",
    "\n",
    "            projection_func = partial(pyproj.transform, wgs_proj, utm_proj)\n",
    "\n",
    "            utm_poly = transform(projection_func, ft_poly)\n",
    "            pix_poly = geometry.Polygon([lonlat2pixXY(c,dt) for c in list(utm_poly.exterior.coords)])\n",
    "\n",
    "            axs[0].imshow((np.swapaxes(np.swapaxes(arr_SPOT.data,0,2),0,1)/256).clip(0.,1.))\n",
    "            xs,ys = pix_poly.exterior.xy\n",
    "            axs[0].plot(xs,ys,c='c',linewidth=2)\n",
    "            \n",
    "            axs[0].set_title('SPOT {}, 10m/px, , {:d}x{:d}px'.format(scenes[0].properties.date,arr_SPOT.shape[1],arr_SPOT.shape[2]), fontsize=20)\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        scenes, ctx = dl.scenes.search(\n",
    "            ft_box,\n",
    "            products=['sentinel-2:L1C'],\n",
    "            start_datetime='2018-09-01',  end_datetime='2018-12-31', cloud_fraction=0.2, limit=10,\n",
    "            )\n",
    "        \n",
    "        if len(scenes)>0:\n",
    "            scenes = sorted(scenes, key=lambda k: k.properties.cloud_fraction, reverse=False)\n",
    "\n",
    "            arr_S2 = scenes[0].ndarray(\"red green blue\", ctx)\n",
    "\n",
    "            for s in scenes[1:]:\n",
    "                fill_por = np.sum(arr_S2>0)/np.prod([*arr_S2.shape])\n",
    "                #print (fill_por, np.sum(arr_S2), np.prod([*arr_S2.shape]))\n",
    "                new_arr = s.ndarray(\"red green blue\", ctx)\n",
    "                #print ('shapes',new_arr.shape, np.sum(new_arr>0))\n",
    "\n",
    "                arr_S2[new_arr.mask==False]=new_arr.data[new_arr.mask==False]\n",
    "\n",
    "\n",
    "            scene_crs = scenes[0].properties['crs']\n",
    "            dt = scenes[0].properties['geotrans']\n",
    "            dt_shapely = [dt[1],dt[2],dt[4],dt[5],dt[0],dt[3]]\n",
    "\n",
    "            WGS84 = \"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\"\n",
    "\n",
    "            wgs_proj = pyproj.Proj(WGS84)\n",
    "            utm_proj = pyproj.Proj(\"+init=\"+scene_crs, preserve_units=True)\n",
    "\n",
    "\n",
    "            dt[0] = utm_proj(*ctx.bounds[0:2])[0]\n",
    "            dt[3] = utm_proj(*ctx.bounds[2:])[1]\n",
    "\n",
    "            projection_func = partial(pyproj.transform, wgs_proj, utm_proj)\n",
    "\n",
    "            utm_poly = transform(projection_func, ft_poly)\n",
    "            pix_poly = geometry.Polygon([lonlat2pixXY(c,dt) for c in list(utm_poly.exterior.coords)])\n",
    "\n",
    "            axs[1].imshow((np.swapaxes(np.swapaxes(arr_S2.data,0,2),0,1)/10000*2.5).clip(0.,1.))\n",
    "            xs,ys = pix_poly.exterior.xy\n",
    "            axs[1].plot(xs,ys,c='c',linewidth=2)\n",
    "        axs[1].set_title('Sentinel-2 (Q4 2018), 1.5m/px, , {:d}x{:d}px'.format(arr_S2.shape[1],arr_S2.shape[2]), fontsize=20)\n",
    "        fig.suptitle(f'uid: {row[\"unique_id\"]},lon:{row[\"geometry\"].representative_point().x:.5f},lat:{row[\"geometry\"].representative_point().y:.5f}', fontsize=26)\n",
    "        #plt.tight_layout()\n",
    "        fig.savefig(os.path.join(root,'data','hand_verify',str(row['unique_id'])+'.png'))\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "    \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(os.path.join(root,'data','ABCD_finalized.geojson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_labels = glob.glob(os.path.join(root,'data','hand_verify','pos','*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_labels = glob.glob(os.path.join(root,'data','hand_verify','neg','*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_labels = glob.glob(os.path.join(root,'data','hand_verify','ind','*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = [f.split('/')[-1].split('.')[0] for f in pos_labels+neg_labels+ind_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [1e2,1e3,1e4,1e5,1e6,1e9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_ids = [int(ii) for ii in all_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(len(bins)-1):\n",
    "    print (ii,((gdf['area']>bins[ii]) & (gdf['area']<=bins[ii+1])).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(len(bins)-1):\n",
    "    print (len(gdf.loc[gdf['unique_id'].isin(slice_ids) & (gdf['area']>bins[ii]) &(gdf['area']<=bins[ii+1]),:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = {ii:gdf.loc[(gdf['area']>bins[ii]) &(gdf['area']<=bins[ii+1]),'unique_id'].values.tolist() for ii in range(len(bins)-1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(range(7),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_0 = np.random.choice(ids[0],0).tolist()\n",
    "ids_3 = np.random.choice(ids[3],0).tolist()\n",
    "ids_4 = np.random.choice(ids[4],10).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect_set = gdf.iloc[np.random.choice(range(len(gdf)),N_inspect),:]\n",
    "inspect_set = gdf.loc[gdf['unique_id'].isin(ids_0+ids_3+ids_4),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in inspect_set.iterrows():\n",
    "    print (row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in inspect_set.iloc[0:,].iterrows():\n",
    "    print (row[0])#['unique_id'])\n",
    "    inspect_sample(row[1],src = 'google')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ids = [int(f.split('/')[-1].split('.')[0]) for f in pos_labels]\n",
    "neg_ids = [int(f.split('/')[-1].split('.')[0]) for f in neg_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_dict = {}\n",
    "for ii in range(len(bins)-1):\n",
    "    pos = ((gdf['unique_id'].isin(pos_ids)) & (gdf['area']>bins[ii]) & (gdf['area']<=bins[ii+1])).sum()\n",
    "    neg = ((gdf['unique_id'].isin(neg_ids)) & (gdf['area']>bins[ii]) & (gdf['area']<=bins[ii+1])).sum()\n",
    "    mu = pos/(pos+neg)\n",
    "    twosigma = 1.96/2/np.sqrt(pos+neg)\n",
    "    \n",
    "    precision_dict[ii] = {\n",
    "        'ii':ii,\n",
    "        'm':pos,\n",
    "        'N':neg+pos,\n",
    "        'mu':mu,\n",
    "        '2sigma':twosigma\n",
    "    }\n",
    "    \n",
    "    print (ii,pos,neg, mu, twosigma)\n",
    "    #m /n +- 1.96/2/sqrt(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = len(gdf[gdf['unique_id'].isin(pos_ids)])\n",
    "neg = len(gdf[gdf['unique_id'].isin(neg_ids)])\n",
    "print (pos,neg, pos/(pos+neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(478+196+194)/(478+196+194+13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://math.stackexchange.com/questions/462404/regarding-calculating-the-bias-of-coin-with-uncertainty"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
