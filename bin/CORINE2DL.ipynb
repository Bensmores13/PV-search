{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest CORINE Land Cover Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will ingest CORINE land cover data onto the DL platform. CORINE is the European Economic Area's land cover dataset and is available for the years 1990, 2000, 2006, 2012, and 2018. The dataset uses 44 classes to describe land cover, ranging from the natural to built environment. The dataset is built from vector data collected from the devolved EEA member states. The vector land cover data is developed using high- and medium-resolution earth observation imagery as well as in-situ data. The minimum mapping unit for the dataset is 0.25 square kilometers for areal phenomena and 100m for linear phenomena. See https://land.copernicus.eu/pan-european/corine-land-cover."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORINE land cover data is provided as vector or 100m raster files. For various purposes, it would be useful to have CORINE land cover data as 10m rasters. Let's grab the CORINE vector data and store it as a DL product at 10m resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time, logging, sys, geojson, pickle\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import geometry\n",
    "import numpy as np\n",
    "from shapely.affinity import affine_transform\n",
    "from shapely import wkt\n",
    "from skimage.measure import block_reduce\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "from osgeo import ogr\n",
    "\n",
    "import descarteslabs as dl\n",
    "from descarteslabs.catalog import Product\n",
    "from descarteslabs.catalog import Image as dl_Image\n",
    "from descarteslabs.catalog import ClassBand, DataType, Resolution, ResolutionUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fetch the data**\n",
    "\n",
    "The following steps will save the CORINE data to this local node for processing.\n",
    "- Make a Copernicus account \n",
    "- For your selected year, generate a download link\n",
    "- download the zip file: `wget <http://path/to/your/zipfile.zip>`\n",
    "- open a terminal and navigate to your zipfile\n",
    "- unzip the zipfile and its nested zipfile: 2x `unzip <path/to/your/zipfile.zip>`\n",
    "- set the `corine_path` variable below to the root of the unzipped directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Workflow**\n",
    "\n",
    "The workflow for creating the CORINE data will be as follows:\n",
    "\n",
    "- Load the CORINE class encoding\n",
    "- Create a DL product and single band\n",
    "- Load the CORINE scope countries\n",
    "- fetch the tiles for the scope countries\n",
    "- load the vector database \n",
    "- for each tile:\n",
    "  - filter the database and push a geojson FeatureCollection to DL Storage\n",
    "  - deploy the rasterising function on DL Tasks which\n",
    "    - fetches the FeatureCollection for the tile\n",
    "    - rasterises it at 1m (for nice crisp lines between objects)\n",
    "    - aggregates to 10m \n",
    "    - pushes the image to the DL product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['corine_path'] = '/home/jovyan/solar-pv-global-inventory/data/CORINE/clc2012_clc2006_v2018_20_fgdb'  # path to the geodatabase\n",
    "params['year'] = '2006' \n",
    "params['gdb_fname'] = 'CLC2012_CLC2006_V2018_20.gdb'\n",
    "params['tilesize'] = 5000 # size of the tiles to be used for rasterisation\n",
    "params['product_params'] = {'_id':'corine-land-cover',\n",
    "                            'name':'CORINE land cover product for re-rasterised CORINE vector layers'}\n",
    "params['band_params'] = {'name':'CLC_class',\n",
    "                         'data_range':(0,255),\n",
    "                         'display_range':(0,50),\n",
    "                         'resolution':10, \n",
    "                         'index':0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get classes from the legend csv included with the data\n",
    "classes = pd.read_csv(os.path.join(params['corine_path'],'Legend','CLC_legend.csv'), sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = (classes['CLC_CODE'].astype(str) +': '+ classes['LABEL3']).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['111: Continuous urban fabric',\n",
       " '112: Discontinuous urban fabric',\n",
       " '121: Industrial or commercial units',\n",
       " '122: Road and rail networks and associated land',\n",
       " '123: Port areas',\n",
       " '124: Airports',\n",
       " '131: Mineral extraction sites',\n",
       " '132: Dump sites',\n",
       " '133: Construction sites',\n",
       " '141: Green urban areas',\n",
       " '142: Sport and leisure facilities',\n",
       " '211: Non-irrigated arable land',\n",
       " '212: Permanently irrigated land',\n",
       " '213: Rice fields',\n",
       " '221: Vineyards',\n",
       " '222: Fruit trees and berry plantations',\n",
       " '223: Olive groves',\n",
       " '231: Pastures',\n",
       " '241: Annual crops associated with permanent crops',\n",
       " '242: Complex cultivation patterns',\n",
       " '243: Land principally occupied by agriculture, with significant areas of natural vegetation',\n",
       " '244: Agro-forestry areas',\n",
       " '311: Broad-leaved forest',\n",
       " '312: Coniferous forest',\n",
       " '313: Mixed forest',\n",
       " '321: Natural grasslands',\n",
       " '322: Moors and heathland',\n",
       " '323: Sclerophyllous vegetation',\n",
       " '324: Transitional woodland-shrub',\n",
       " '331: Beaches, dunes, sands',\n",
       " '332: Bare rocks',\n",
       " '333: Sparsely vegetated areas',\n",
       " '334: Burnt areas',\n",
       " '335: Glaciers and perpetual snow',\n",
       " '411: Inland marshes',\n",
       " '412: Peat bogs',\n",
       " '421: Salt marshes',\n",
       " '422: Salines',\n",
       " '423: Intertidal flats',\n",
       " '511: Water courses',\n",
       " '512: Water bodies',\n",
       " '521: Coastal lagoons',\n",
       " '522: Estuaries',\n",
       " '523: Sea and ocean',\n",
       " '999: NODATA',\n",
       " '990: UNCLASSIFIED LAND SURFACE',\n",
       " '995: UNCLASSIFIED WATER BODIES']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Product and Band"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Product**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = Product.get('oxford-university:corine-land-cover')#(params['product_params']['_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not product:\n",
    "    product = Product(id=params['product_params']['_id'], \n",
    "                      name=params['product_params']['name'])\n",
    "    product.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [bb for bb in product.bands().limit(2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Band**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not bands:\n",
    "    band = ClassBand(name=params['band_params']['name'], product=product)\n",
    "    band.data_type = DataType.BYTE\n",
    "    band.data_range = params['band_params']['data_range']\n",
    "    band.display_range = params['band_params']['display_range']\n",
    "    band.resolution = Resolution(unit=ResolutionUnit.METERS, value=params['band_params']['resolution'])\n",
    "    band.band_index = params['band_params']['index']\n",
    "    band.class_labels = class_labels\n",
    "    band.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Delete product and images if necessary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### delete the product if it needs to be remade\n",
    "# status = product.delete_related_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Scope Countries and Fetch Country Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load scope countries from the CLC metadata\n",
    "scope_countries = pd.read_excel(os.path.join(params['corine_path'],'CLC_country_coverage_v20.xls'), skiprows=4)\n",
    "scope_countries = scope_countries[scope_countries['ISO code'].str.len()==2] # drop trailing notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_shapes = {}\n",
    "for country in scope_countries.Country.values.tolist():\n",
    "    res = [r for r in dl.Places().find(country.lower().replace(' ','-')) if r['placetype']=='country']\n",
    "    if res:\n",
    "        country_shapes[country] = geometry.shape(dl.Places().shape(res[0]['slug'], geom='medium')['geometry'])\n",
    "    else: \n",
    "        print ('Nothing found!', country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### add montenegro and france manually\n",
    "res = [r for r in dl.Places().find('montenegro') if r['placetype']=='country']\n",
    "country_shapes['Monte Negro'] = geometry.shape(dl.Places().shape(res[0]['slug'], geom='medium')['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### add France from natural earth\n",
    "ne = gpd.read_file(os.path.join(params['corine_path'],'ne_10m_countries.gpkg'))\n",
    "country_shapes['France'] = ne[ne.ISO_A2=='FR'].iloc[0].geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast dict to geopandas geoseries\n",
    "gds_countries = gpd.GeoSeries(data=country_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds_countries.plot(figsize=(6,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch tiles for all countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extents_box = geometry.box(-40,20,60,88) #minx, miny, maxx, maxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip countries to the bounding box of CORINE and reduce country shapes to a multipolygon\n",
    "countries_mp = gpd.clip(gds_countries,extents_box).geometry.unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tile = dl.Raster().dltile_from_latlon(lat=51.744674, lon=-1.246004, resolution=10, tilesize=500, pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the tiles\n",
    "tiles = dl.Raster().dltiles_from_shape(\n",
    "    resolution=params['band_params']['resolution'],\n",
    "    tilesize=params['tilesize'],\n",
    "    pad=0,\n",
    "    shape=countries_mp)\n",
    "print (len(tiles['features']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use geopandas to quickly plot the tiles\n",
    "tile_polys = [geometry.shape(t['geometry']) for t in tiles['features']]\n",
    "gds_tiles = gpd.GeoSeries(tile_polys)\n",
    "# gds_tiles.plot(figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds_tiles.plot(figsize=(12,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the gdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### try loading into a GeoDataFrame...\n",
    "# gdf = gpd.read_file(os.path.join(params['corine_path'],params['gdb_fname']))\n",
    "# ... this takes way too long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile2fcstorage(tile, params):\n",
    "    logger = logging.getLogger(tile['properties']['key'])\n",
    "    try:\n",
    "        tic = time.time()\n",
    "        storage_client = dl.Storage()\n",
    "\n",
    "\n",
    "        # handle tile\n",
    "        logger.info(f'handling file {time.time()-tic}')\n",
    "        tile_shp = geometry.shape(tile.geometry)\n",
    "        tile_gds = gpd.GeoSeries(tile_shp, crs='EPSG:4326')\n",
    "        tile_LAEA = tile_gds.to_crs('EPSG:3035').geometry[0]\n",
    "        tile_utm = tile_gds.to_crs(tile['properties']['cs_code']).geometry[0]\n",
    "\n",
    "        # get fc\n",
    "        logger.info(f'filtering gdb {time.time()-tic}')\n",
    "        driver = ogr.GetDriverByName(\"OpenFileGDB\")\n",
    "        dataSource = driver.Open(os.path.join(params['corine_path'],params['gdb_fname']), 0)\n",
    "        layer = dataSource.GetLayer()\n",
    "        layer.SetSpatialFilter(ogr.CreateGeometryFromWkt(tile_LAEA.wkt))\n",
    "        logger.info(f'getting features {time.time()-tic}')\n",
    "        features=[]\n",
    "        for feature in layer:\n",
    "            #print (dir(feature))\n",
    "            #print (feature.items())\n",
    "            #print (dir (feature.geometry()))\n",
    "            #print ('lingeom',feature.geometry().GetLinearGeometry())\n",
    "            try:\n",
    "                features.append(feature.ExportToJson())\n",
    "            except Exception as e:\n",
    "                logger.exception('message')\n",
    "                logger.info('trying via wkt')\n",
    "                ft_wkt = feature.geometry().ExportToWkt()\n",
    "                print (ft_wkt[0:20])\n",
    "                if ft_wkt.split(' ')[0]=='MULTISURFACE':\n",
    "                    features.append(json.dumps(geojson.Feature(\n",
    "                        geometry=wkt.loads(feature.geometry().GetLinearGeometry().ExportToWkt()),\n",
    "                        properties=feature.items())\n",
    "                    ))\n",
    "                else:\n",
    "                    raise\n",
    "            \n",
    "        if len(features)==0:\n",
    "            logger.info(f'zero features. Write blank to Storage. {time.time()-tic}')\n",
    "            json.dump(geojson.FeatureCollection([]), open(os.path.join(params['corine_path'],'tile_gj',params['year']+'_'+tile['properties']['key']+'.geojson'), 'w'))\n",
    "            storage_client.set_file(params['year']+'_'+tile['properties']['key']+'.geojson',os.path.join(params['corine_path'],'tile_gj',params['year']+'_'+tile['properties']['key']+'.geojson'))\n",
    "        \n",
    "            logger.info(f'write log {time.time()-tic}')\n",
    "            with open(os.path.join(params['corine_path'],'write_log.log'),'a+') as f:\n",
    "                f.write('{}\\r\\n'.format(tile['properties']['key'],time.time()-tic))\n",
    "        \n",
    "            return 0\n",
    "        # \n",
    "        logger.info(f'casting to gdf {time.time()-tic}')\n",
    "        # LAEA projection\n",
    "        gdf = gpd.GeoDataFrame.from_features([json.loads(ft) for ft in features], crs = 'EPSG:3035')\n",
    "\n",
    "        # reproject geometry and buffer to try to fix topology errors\n",
    "        logger.info(f'reprojecting geometry {time.time()-tic}')\n",
    "        gdf.geometry = gdf.geometry.to_crs('+proj=longlat +datum=WGS84 +no_defs ').buffer(0)\n",
    "\n",
    "        # clip to the tile to save space\n",
    "        logger.info(f'clip to tile {time.time()-tic}')\n",
    "        gdf.geometry = gdf.geometry.intersection(tile_shp)\n",
    "\n",
    "        gdf = gdf[~gdf.geometry.is_empty]\n",
    "\n",
    "        # dump to file\n",
    "        logger.info(f'dump to file {time.time()-tic}')\n",
    "        gdf.to_file(os.path.join(params['corine_path'],'tile_gj',params['year']+'_'+tile['properties']['key']+'.geojson'), driver='GeoJSON')\n",
    "\n",
    "        logger.info(f'push to storage {time.time()-tic}')\n",
    "        storage_client.set_file(params['year']+'_'+tile['properties']['key']+'.geojson',os.path.join(params['corine_path'],'tile_gj',params['year']+'_'+tile['properties']['key']+'.geojson'))\n",
    "        \n",
    "        logger.info(f'write log {time.time()-tic}')\n",
    "        with open(os.path.join(params['corine_path'],'write_log.log'),'a+') as f:\n",
    "            f.write('{}\\r\\n'.format(tile['properties']['key'],time.time()-tic))\n",
    "\n",
    "        logger.info(f'DONE {time.time()-tic}')\n",
    "\n",
    "        #print (gdf[725:750])\n",
    "        #fig, ax = plt.subplots(1,1,figsize=(20,20))\n",
    "        #gdf.plot(column='Code_18', ax=ax)\n",
    "    except Exception as e:\n",
    "        logger.exception(\"message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### try running a random tile\n",
    "tile = tiles['features'][np.random.choice(len(tiles['features']))]\n",
    "tile2fcstorage(tile,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run an individual tile\n",
    "# tile = [tt for tt in tiles['features'] if tt['properties']['key']=='5000:0:10.0:28:1:127'][0]\n",
    "# tile2fcstorage(tile,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check if it made it to storage\n",
    "storage_client_local = dl.Storage()\n",
    "storage_client_local.exists(params['year']+'_'+tile['properties']['key']+'.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep and store GeoJSONs using Python multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## see which ones are done\n",
    "if os.path.exists(os.path.join(params['corine_path'],'write_log.log')):\n",
    "    with open(os.path.join(params['corine_path'],'write_log.log'),'r') as f:\n",
    "        done_tiles = f.readlines()\n",
    "else:\n",
    "    done_tiles = []\n",
    "done_tiles = [tt.rstrip() for tt in done_tiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(done_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "print (mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = mp.Pool(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run tiles that aren't done yet\n",
    "run_tiles = [tt for tt in tiles['features'] if tt['properties']['key'] not in done_tiles]\n",
    "print (len(run_tiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### multiprocess the feature fetching and storage\n",
    "pool.starmap(tile2fcstorage, list(zip(run_tiles, [params]*len(run_tiles))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'code': '111', 'description': 'Continuous urban fabric'}, 2: {'code': '112', 'description': 'Discontinuous urban fabric'}, 3: {'code': '121', 'description': 'Industrial or commercial units'}, 4: {'code': '122', 'description': 'Road and rail networks and associated land'}, 5: {'code': '123', 'description': 'Port areas'}, 6: {'code': '124', 'description': 'Airports'}, 7: {'code': '131', 'description': 'Mineral extraction sites'}, 8: {'code': '132', 'description': 'Dump sites'}, 9: {'code': '133', 'description': 'Construction sites'}, 10: {'code': '141', 'description': 'Green urban areas'}, 11: {'code': '142', 'description': 'Sport and leisure facilities'}, 12: {'code': '211', 'description': 'Non-irrigated arable land'}, 13: {'code': '212', 'description': 'Permanently irrigated land'}, 14: {'code': '213', 'description': 'Rice fields'}, 15: {'code': '221', 'description': 'Vineyards'}, 16: {'code': '222', 'description': 'Fruit trees and berry plantations'}, 17: {'code': '223', 'description': 'Olive groves'}, 18: {'code': '231', 'description': 'Pastures'}, 19: {'code': '241', 'description': 'Annual crops associated with permanent crops'}, 20: {'code': '242', 'description': 'Complex cultivation patterns'}, 21: {'code': '243', 'description': 'Land principally occupied by agriculture, with significant areas of natural vegetation'}, 22: {'code': '244', 'description': 'Agro-forestry areas'}, 23: {'code': '311', 'description': 'Broad-leaved forest'}, 24: {'code': '312', 'description': 'Coniferous forest'}, 25: {'code': '313', 'description': 'Mixed forest'}, 26: {'code': '321', 'description': 'Natural grasslands'}, 27: {'code': '322', 'description': 'Moors and heathland'}, 28: {'code': '323', 'description': 'Sclerophyllous vegetation'}, 29: {'code': '324', 'description': 'Transitional woodland-shrub'}, 30: {'code': '331', 'description': 'Beaches, dunes, sands'}, 31: {'code': '332', 'description': 'Bare rocks'}, 32: {'code': '333', 'description': 'Sparsely vegetated areas'}, 33: {'code': '334', 'description': 'Burnt areas'}, 34: {'code': '335', 'description': 'Glaciers and perpetual snow'}, 35: {'code': '411', 'description': 'Inland marshes'}, 36: {'code': '412', 'description': 'Peat bogs'}, 37: {'code': '421', 'description': 'Salt marshes'}, 38: {'code': '422', 'description': 'Salines'}, 39: {'code': '423', 'description': 'Intertidal flats'}, 40: {'code': '511', 'description': 'Water courses'}, 41: {'code': '512', 'description': 'Water bodies'}, 42: {'code': '521', 'description': 'Coastal lagoons'}, 43: {'code': '522', 'description': 'Estuaries'}, 44: {'code': '523', 'description': 'Sea and ocean'}, 45: {'code': '999', 'description': 'NODATA'}, 46: {'code': '990', 'description': 'UNCLASSIFIED LAND SURFACE'}, 47: {'code': '995', 'description': 'UNCLASSIFIED WATER BODIES'}}\n"
     ]
    }
   ],
   "source": [
    "class_labels_dict = {kk+1:{'code':class_labels[kk].split(': ')[0],'description':class_labels[kk].split(': ')[-1]} for kk in range(len(class_labels))}\n",
    "print(class_labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(class_labels_dict, open('./class_labels_CORINE.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the rasteriser on DL.Tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile2img(tile, params, class_labels_dict):\n",
    "    \n",
    "    import logging, json, sys\n",
    "    from shapely import geometry\n",
    "    \n",
    "    import geopandas as gpd\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    import descarteslabs as dl\n",
    "    print (dl.__version__)\n",
    "    from descarteslabs.catalog import Image, Product\n",
    "    \n",
    "    from shapely.affinity import affine_transform\n",
    "    from skimage.measure import block_reduce\n",
    "    from PIL import ImageDraw\n",
    "    from PIL import Image as pilImage\n",
    "    \n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "    \n",
    "    storage_client = dl.Storage()\n",
    "    \n",
    "    logger = logging.getLogger(tile['properties']['key'])\n",
    "    logger.info('Get Product')\n",
    "    \n",
    "    product = Product.get_or_create('oxford-university:corine-land-cover')\n",
    "    \n",
    "    def xyz2xy(coord_seq):\n",
    "        return [(t[0],t[1]) for t in list(coord_seq)]\n",
    "    \n",
    "    logger.info('handle tile...')\n",
    "    tile_shp = geometry.shape(tile['geometry'])\n",
    "    tile_gds = gpd.GeoSeries(tile_shp, crs='EPSG:4326')\n",
    "    tile_LAEA = tile_gds.to_crs('EPSG:3035').geometry[0]\n",
    "    tile_utm = tile_gds.to_crs(tile['properties']['cs_code']).geometry[0]\n",
    "    \n",
    "    BL = geometry.Point(tile_utm.bounds[0], tile_utm.bounds[1]) # bottom left in UTM\n",
    "    \n",
    "    logger.info(f'BL {BL}')\n",
    "    \n",
    "    logger.info('get GDF')\n",
    "    # load data\n",
    "    \n",
    "    features  = json.loads(storage_client.get(params['year']+'_'+tile['properties']['key']+'.geojson'))['features']\n",
    "    if len(features)==0:\n",
    "        logger.info('No features!')\n",
    "        return {'tile':tile['properties']['key'],\n",
    "               'n_features':0}\n",
    "    \n",
    "    df = pd.DataFrame.from_records([ft['properties'] for ft in features])\n",
    "    geometries = [geometry.shape(ft['geometry']) for ft in features]\n",
    "  \n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geometries, crs = {'init':'epsg:4326'})\n",
    "    #gdf = gpd.read_file(os.path.join(params['corine_path'],'gdf_'+tile['properties']['key']+'.geojson'))\n",
    "    \n",
    "    # convert to utm\n",
    "    gdf = gdf.to_crs(tile['properties']['cs_code'])\n",
    "    print (gdf)\n",
    "    \n",
    "    logger.info('class array')\n",
    "    class_array = np.zeros((params['tilesize'], params['tilesize'],50),dtype = np.int8)\n",
    "    \n",
    "    slice_tilesize=int(params['tilesize']/10)   # 500px -> 5km\n",
    "    \n",
    "    for ii_x in range(int(params['tilesize']/slice_tilesize)):\n",
    "        for ii_y in range(int(params['tilesize']/slice_tilesize)):\n",
    "            # create the mask for the slice\n",
    "            \n",
    "            logger.info(f'ii_x, ii_y: {ii_x}, {ii_y}')\n",
    "            slice_mask = np.zeros((slice_tilesize, slice_tilesize, 50), dtype = np.int8)\n",
    "            big_slice_mask = np.zeros((slice_tilesize*10, slice_tilesize*10, 50), dtype = np.int8) # make slice tilesize 10x larger to 1m resolution\n",
    "            \n",
    "            # get the slice affine transform\n",
    "            a = e = 1/1 # stretch along-axis 1m/px\n",
    "            b = d = 0 # rotate across-axis 0m/px\n",
    "            x_off = - (BL.x + ii_x*slice_tilesize*10) / 1 # offset from cartesian origin in pixel coordinates\n",
    "            y_off = - (BL.y + ii_y*slice_tilesize*10) / 1 # offset from cartesian origin in pixel coordinates\n",
    "            GT = [a,b,d,e,x_off,y_off] # GeoTransform Matrix\n",
    "            \n",
    "            ### draw all objects\n",
    "            for class_code in list(class_labels_dict.keys()):\n",
    "                # create Image object\n",
    "                im = pilImage.fromarray(big_slice_mask[:,:,int(class_code)], mode='L')\n",
    "\n",
    "                # create ImageDraw object\n",
    "                draw = ImageDraw.Draw(im)\n",
    "                \n",
    "                # draw objects\n",
    "                geometries = gdf[gdf.Code_06==class_labels_dict[class_code]['code']].geometry.values\n",
    "                \n",
    "                for geom_utm in geometries:\n",
    "                    geom_px = affine_transform(geom_utm, GT)\n",
    "                    \n",
    "                    if geom_px.type=='Polygon':\n",
    "                        # draw the polygon\n",
    "                        draw.polygon(xyz2xy(geom_px.exterior.coords), fill=1)\n",
    "\n",
    "                        # un-draw any holes in the polygon...\n",
    "                        for hole in geom_px.interiors:\n",
    "                            draw.polygon(xyz2xy(hole.coords), fill=0)\n",
    "                        \n",
    "                    elif geom_px.type=='MultiPolygon':\n",
    "                        for subgeom in list(geom_px):\n",
    "                            # draw the polygon\n",
    "                            draw.polygon(xyz2xy(subgeom.exterior.coords), fill=1)\n",
    "\n",
    "                            # un-draw any holes in the polygon...\n",
    "                            for hole in subgeom.interiors:\n",
    "                                draw.polygon(xyz2xy(hole.coords), fill=0)\n",
    "                \n",
    "                # return the image object to the mask array\n",
    "                big_slice_mask[:,:,int(class_code)] = np.array(im)\n",
    "                \n",
    "            ### reduce the mask array\n",
    "            ### draw all objects\n",
    "            for class_code in class_labels_dict.keys():\n",
    "                # create Image object\n",
    "                slice_mask[:,:,int(class_code)] = block_reduce(big_slice_mask[:,:,int(class_code)], (10,10), np.sum)\n",
    "                \n",
    "            class_array[ii_y*slice_tilesize:(ii_y+1)*slice_tilesize,ii_x*slice_tilesize:(ii_x+1)*slice_tilesize,:] = slice_mask #np.swapaxes(slice_mask,0,1)\n",
    "            \n",
    "    logger.info(f'Got full array')\n",
    "    #class_array = np.swapaxes(np.argmax(class_array, axis=-1),0,1)\n",
    "    class_array = np.flip(np.argmax(class_array, axis=-1), axis=0)\n",
    "    \n",
    "    logger.info(f'Get raster info')\n",
    "    raster_info = {\n",
    "        'driverShortName':'MEM',\n",
    "        'driverLongName': 'In Memory Raster',\n",
    "        'files':[],\n",
    "        'size':[params['tilesize'],params['tilesize']],\n",
    "        'coordinateSystem':{'wkt':tile['properties']['wkt']},\n",
    "        'geotrans': tile['properties']['geotrans'],\n",
    "        'cs_code':tile['properties']['cs_code'],\n",
    "         'metadata': {},\n",
    "         'cornerCoordinates': {'upperLeft': [round(tt) for tt in list(tile_utm.exterior.coords)[3]],\n",
    "                              'lowerLeft': [round(tt) for tt in list(tile_utm.exterior.coords)[0]],\n",
    "                              'lowerRight': [round(tt) for tt in list(tile_utm.exterior.coords)[1]],\n",
    "                              'upperRight': [round(tt) for tt in list(tile_utm.exterior.coords)[2]],\n",
    "                              'center': [round(tile_utm.centroid.x), round(tile_utm.centroid.y)]},\n",
    "         'wgs84Extent': geometry.mapping(geometry.box(*tile_shp.bounds)),\n",
    "     'bands': [{'band': 1}],\n",
    "\n",
    "    }\n",
    "    \n",
    "    \n",
    "    logger.info(f'Generating image')\n",
    "\n",
    "    image = Image(product=product, name=params['year']+'_'+tile['properties']['key'].replace(':','_'), acquired=params['year']+\"-12-31\", acquired_end=params['year']+\"-12-31\", cs_code=tile['properties']['cs_code'], geotrans=tile['properties']['geotrans'])\n",
    "\n",
    "    logger.info(f'Uploading image')\n",
    "    \n",
    "    image.upload_ndarray(class_array.astype(np.int8),raster_meta=raster_info)\n",
    "\n",
    "            \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = dl.Tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = tasks.create_function(\n",
    "            tile2img,\n",
    "            image='us.gcr.io/dl-ci-cd/images/tasks/public/py3.7:v1.1.1',\n",
    "            name='tile2img-v16-2006',\n",
    "            requirements=[],\n",
    "            maximum_concurrency=500,\n",
    "            memory='3.5Gi',\n",
    "            retry_count=0,\n",
    "            task_timeout=21600,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run a local or test file\n",
    "# tile = tiles['features'][np.random.choice(len(tiles['features']))]\n",
    "\n",
    "## local:\n",
    "# tile2img(tile, params, class_labels_dict)\n",
    "\n",
    "## remote:\n",
    "# fn(tile, params, class_labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Deploy all tiles\n",
    "all_tasks = []\n",
    "for ii_t, tile in enumerate(tiles['features']):\n",
    "    if ii_t % 100==0:\n",
    "        print (ii_t)\n",
    "    all_tasks.append(fn(tile, params, class_labels_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
